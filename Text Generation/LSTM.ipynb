{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cdeed3b",
   "metadata": {},
   "source": [
    "# LSTM Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c652c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding, TimeDistributed, Activation\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6daaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a GPU is available and enable memory growth\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print('No GPU found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = open('scifi/internet_archive_scifi_v3.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset selection because the whole is large\n",
    "input_text=(input_text[3187:700000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111042b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data\n",
    "text = input_text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "words = text.split()\n",
    "\n",
    "# Create a dictionary mapping words to integer indices\n",
    "word_to_index = dict((w, i) for i, w in enumerate(set(words)))\n",
    "index_to_word = dict((i, w) for i, w in enumerate(set(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10\n",
    "step = 1\n",
    "sequences = []\n",
    "next_words = []\n",
    "for i in range(0, len(words) - seq_length, step):\n",
    "    sequences.append(words[i:i + seq_length])\n",
    "    next_words.append(words[i + seq_length])\n",
    "\n",
    "X = np.zeros((len(sequences), seq_length, len(word_to_index)), dtype=np.bool)\n",
    "y = np.zeros((len(next_words), len(word_to_index)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(sequences):\n",
    "    for j, word in enumerate(sequence):\n",
    "        X[i, j, word_to_index[word]] = 1\n",
    "    y[i, word_to_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46159ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(seq_length, len(word_to_index))))\n",
    "model.add(tf.keras.layers.Dense(len(word_to_index), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ab2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM model\n",
    "model.fit(X, y, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, prediction_length):\n",
    "  #Generate text\n",
    "  seed_text = input_text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "  generated_text = seed_text\n",
    "  for i in range(prediction_length):\n",
    "      # Convert seed text to integer encoding\n",
    "      x = np.zeros((1, seq_length, len(word_to_index)), dtype=bool)\n",
    "      for j, word in enumerate(seed_text.split()):\n",
    "          x[0, j, word_to_index[word]] = 1\n",
    "      # Predict next word\n",
    "      prediction = model.predict(x, verbose=0)[0]\n",
    "      index = np.argmax(prediction)\n",
    "      next_word = index_to_word[index]\n",
    "      \n",
    "      # Update seed text and generated text\n",
    "      generated_text += ' ' + next_word\n",
    "      seed_text = ' '.join(seed_text.split()[1:] + [next_word])\n",
    "  return(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('In the kitchen he',20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
