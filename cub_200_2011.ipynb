{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPFmn1WzNn1idN/sGMnlx8R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"556abefd8a834bf6afe4ec1e236ed292":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12e10842083b415191fdb378b5f4cd57","IPY_MODEL_010543922a604fa7932bb63736e4c438","IPY_MODEL_0b29749dd06f458bb086bb6e1e9b5ec0"],"layout":"IPY_MODEL_977e87d285ce4e2289ead7ce2731d403"}},"12e10842083b415191fdb378b5f4cd57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eed89c16867440e391cf14ac498c8570","placeholder":"​","style":"IPY_MODEL_5cd6067d9fd94c03b514cb3c06cec17a","value":"100%"}},"010543922a604fa7932bb63736e4c438":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97efd50438de485c9e94091a2cc5810c","max":46830571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbc29a1ce9614b18a5042f6c516c32e0","value":46830571}},"0b29749dd06f458bb086bb6e1e9b5ec0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8eec1a22a2834f19bf24d581f7e1421f","placeholder":"​","style":"IPY_MODEL_cbab6a703bdf4a6993925194fdf1b709","value":" 44.7M/44.7M [00:00&lt;00:00, 159MB/s]"}},"977e87d285ce4e2289ead7ce2731d403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed89c16867440e391cf14ac498c8570":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cd6067d9fd94c03b514cb3c06cec17a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97efd50438de485c9e94091a2cc5810c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbc29a1ce9614b18a5042f6c516c32e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8eec1a22a2834f19bf24d581f7e1421f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbab6a703bdf4a6993925194fdf1b709":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LCS5DwEBJru","executionInfo":{"status":"ok","timestamp":1677816305147,"user_tz":0,"elapsed":21688,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}},"outputId":"3cfab4ef-88ff-47a7-aba3-f88900b23e49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["file_path_train='/content/drive/My Drive/Colab Notebooks/task 2/CUB_200_2011/images_new/train'\n","file_path_test='/content/drive/My Drive/Colab Notebooks/task 2/CUB_200_2011/images_new/test'"],"metadata":{"id":"mA17_-iqBUtk","executionInfo":{"status":"ok","timestamp":1677816305148,"user_tz":0,"elapsed":6,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import models, transforms, datasets\n","from sklearn.metrics import classification_report,confusion_matrix\n","import numpy as np"],"metadata":{"id":"GdJmmaQtBUwr","executionInfo":{"status":"ok","timestamp":1677816309622,"user_tz":0,"elapsed":4479,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"UQM-3Fu0gMKB","executionInfo":{"status":"ok","timestamp":1677816309949,"user_tz":0,"elapsed":5,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["transform_train = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"FwPAvnmcMXSY","executionInfo":{"status":"ok","timestamp":1677816309949,"user_tz":0,"elapsed":4,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["trainset = torchvision.datasets.ImageFolder(root=file_path_train, transform=transform_train)\n","testset = torchvision.datasets.ImageFolder(root=file_path_test, transform=transform_test)\n","\n","torch.manual_seed(42)\n","\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n","test_loader  = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n","\n","classes = trainset.classes\n","\n","# Print the number of images in each set\n","print('Number of images in training set:', len(trainset))\n","print('Number of images in test set:', len(testset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfneWl7mMXU8","executionInfo":{"status":"ok","timestamp":1677816356384,"user_tz":0,"elapsed":46439,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}},"outputId":"3780887b-f47c-4293-9a00-68b4c41ba798"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images in training set: 5994\n","Number of images in test set: 5794\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["model = models.resnet18(pretrained=True)\n","num_features = model.fc.in_features\n","model.fc = nn.Linear(num_features, 200)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["556abefd8a834bf6afe4ec1e236ed292","12e10842083b415191fdb378b5f4cd57","010543922a604fa7932bb63736e4c438","0b29749dd06f458bb086bb6e1e9b5ec0","977e87d285ce4e2289ead7ce2731d403","eed89c16867440e391cf14ac498c8570","5cd6067d9fd94c03b514cb3c06cec17a","97efd50438de485c9e94091a2cc5810c","cbc29a1ce9614b18a5042f6c516c32e0","8eec1a22a2834f19bf24d581f7e1421f","cbab6a703bdf4a6993925194fdf1b709"]},"id":"e6iRYFqjMXXi","executionInfo":{"status":"ok","timestamp":1677816357274,"user_tz":0,"elapsed":899,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}},"outputId":"e5354cf4-c512-4094-88d7-954b84510ff9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"556abefd8a834bf6afe4ec1e236ed292"}},"metadata":{}}]},{"cell_type":"code","source":["model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIbH77pbhgCW","executionInfo":{"status":"ok","timestamp":1677816361159,"user_tz":0,"elapsed":3889,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}},"outputId":"8f9909ad-0690-4ad9-e57e-0f8e79525c1c"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=200, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"FdVs51WeyJU7","executionInfo":{"status":"ok","timestamp":1677816361160,"user_tz":0,"elapsed":7,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 15\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    running_loss += loss.item()\n","    print('[Epoch %d] Loss: %.3f' %\n","          (epoch + 1, running_loss /100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vdEE0zzMjKt","outputId":"b71173a9-ce4a-4116-c92c-9157dae2613c","executionInfo":{"status":"ok","timestamp":1677817914308,"user_tz":0,"elapsed":1553153,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch 1] Loss: 9.726\n","[Epoch 2] Loss: 8.067\n","[Epoch 3] Loss: 6.689\n","[Epoch 4] Loss: 5.795\n","[Epoch 5] Loss: 5.067\n","[Epoch 6] Loss: 4.545\n","[Epoch 7] Loss: 4.111\n","[Epoch 8] Loss: 3.762\n","[Epoch 9] Loss: 3.541\n","[Epoch 10] Loss: 3.230\n","[Epoch 11] Loss: 3.111\n","[Epoch 12] Loss: 2.884\n","[Epoch 13] Loss: 2.740\n","[Epoch 14] Loss: 2.596\n","[Epoch 15] Loss: 2.499\n","[Epoch 16] Loss: 2.439\n","[Epoch 17] Loss: 2.364\n","[Epoch 18] Loss: 2.250\n","[Epoch 19] Loss: 2.143\n","[Epoch 20] Loss: 2.090\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/task 2/CUB_200_2011/checkpoint/model.pt')"],"metadata":{"id":"TPiAvOVVP_aU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_weight = torch.load('/content/drive/My Drive/Colab Notebooks/task 2/CUB_200_2011/checkpoint/model.pt')"],"metadata":{"id":"FbZ9o40IWSV7","executionInfo":{"status":"ok","timestamp":1677819280214,"user_tz":0,"elapsed":2752,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Load the state dictionary into the model\n","model.load_state_dict(load_weight)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4XAE2mecYJJ","executionInfo":{"status":"ok","timestamp":1677819281587,"user_tz":0,"elapsed":2,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}},"outputId":"4dbe8a91-7408-4345-82b9-f941c0ad21a9"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Set the model to evaluation mode\n","model.eval()"],"metadata":{"id":"k74Q2fBkt02j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677819284018,"user_tz":0,"elapsed":4,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}},"outputId":"15e66017-4ec8-49a4-cde1-e9f137b104bf"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=200, bias=True)\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["y_corr=[]\n","y_pre=[]\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        y_corr.extend(labels)\n","        y_pre.extend(predicted)"],"metadata":{"id":"5ATnlNO7J6G1","executionInfo":{"status":"ok","timestamp":1677819333336,"user_tz":0,"elapsed":46391,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["ycorr=torch.tensor(y_corr).detach().cpu().numpy()\n","ypre=torch.tensor(y_pre).detach().cpu().numpy()\n","\n","print(classification_report(ycorr, ypre))"],"metadata":{"id":"qIWuimQSjnAh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677819333337,"user_tz":0,"elapsed":8,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}},"outputId":"3b737a05-4080-4671-a92f-ba1c2bf6b912"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.83      0.69        30\n","           1       0.77      0.77      0.77        30\n","           2       0.65      0.79      0.71        28\n","           3       0.79      0.87      0.83        30\n","           4       0.56      0.64      0.60        14\n","           5       0.71      0.91      0.80        11\n","           6       0.86      0.78      0.82        23\n","           7       0.85      0.61      0.71        18\n","           8       0.42      0.28      0.33        29\n","           9       0.96      0.87      0.91        30\n","          10       0.57      0.67      0.62        30\n","          11       1.00      1.00      1.00        26\n","          12       0.87      0.90      0.89        30\n","          13       0.89      0.83      0.86        30\n","          14       0.87      0.96      0.92        28\n","          15       1.00      0.93      0.96        28\n","          16       0.85      0.85      0.85        27\n","          17       1.00      1.00      1.00        15\n","          18       0.85      0.76      0.80        29\n","          19       0.88      0.76      0.81        29\n","          20       0.97      0.93      0.95        30\n","          21       0.66      0.88      0.75        26\n","          22       0.47      0.66      0.55        29\n","          23       0.88      0.68      0.77        22\n","          24       0.57      0.43      0.49        30\n","          25       0.96      0.77      0.85        30\n","          26       0.41      0.23      0.30        30\n","          27       0.89      0.86      0.88        29\n","          28       0.37      0.33      0.35        30\n","          29       0.28      0.37      0.31        30\n","          30       0.86      0.63      0.73        30\n","          31       0.79      0.65      0.71        23\n","          32       0.54      0.76      0.63        29\n","          33       0.93      0.86      0.89        29\n","          34       0.82      0.93      0.87        30\n","          35       0.93      0.93      0.93        30\n","          36       0.69      0.31      0.43        29\n","          37       0.87      0.67      0.75        30\n","          38       0.41      0.55      0.47        29\n","          39       0.50      0.53      0.52        30\n","          40       0.80      0.80      0.80        30\n","          41       0.95      0.70      0.81        30\n","          42       0.57      0.55      0.56        29\n","          43       0.79      0.87      0.83        30\n","          44       0.66      0.63      0.64        30\n","          45       0.64      0.93      0.76        30\n","          46       0.87      0.90      0.89        30\n","          47       0.91      0.97      0.94        30\n","          48       0.44      0.73      0.55        30\n","          49       0.75      0.70      0.72        30\n","          50       0.73      0.80      0.76        30\n","          51       0.85      0.93      0.89        30\n","          52       0.91      1.00      0.95        30\n","          53       0.79      0.87      0.83        30\n","          54       0.90      0.93      0.92        30\n","          55       0.93      0.87      0.90        30\n","          56       0.97      0.93      0.95        30\n","          57       0.87      0.71      0.78        28\n","          58       0.38      0.37      0.37        30\n","          59       0.46      0.41      0.44        29\n","          60       0.94      0.97      0.95        30\n","          61       0.33      0.30      0.32        30\n","          62       0.72      0.97      0.83        30\n","          63       0.50      0.43      0.46        30\n","          64       0.56      0.50      0.53        20\n","          65       0.58      0.47      0.52        30\n","          66       0.77      0.67      0.71        30\n","          67       0.75      0.80      0.77        30\n","          68       0.82      0.90      0.86        30\n","          69       0.91      0.97      0.94        30\n","          70       0.33      0.20      0.25        30\n","          71       0.50      0.37      0.42        30\n","          72       0.79      0.90      0.84        30\n","          73       0.93      0.90      0.92        30\n","          74       1.00      0.96      0.98        27\n","          75       0.93      0.90      0.92        30\n","          76       0.85      0.93      0.89        30\n","          77       0.73      0.66      0.69        29\n","          78       0.88      0.77      0.82        30\n","          79       0.95      0.63      0.76        30\n","          80       0.90      0.90      0.90        30\n","          81       0.68      0.93      0.79        30\n","          82       0.94      0.97      0.95        30\n","          83       0.83      0.65      0.73        23\n","          84       0.90      0.93      0.92        30\n","          85       0.88      0.77      0.82        30\n","          86       0.92      0.77      0.84        30\n","          87       0.90      0.90      0.90        30\n","          88       0.85      0.77      0.81        30\n","          89       0.81      0.87      0.84        30\n","          90       0.64      0.53      0.58        30\n","          91       0.86      0.83      0.85        30\n","          92       0.97      1.00      0.98        30\n","          93       0.97      0.93      0.95        30\n","          94       0.87      0.87      0.87        30\n","          95       0.85      0.77      0.81        30\n","          96       0.82      0.79      0.81        29\n","          97       0.90      0.90      0.90        30\n","          98       0.90      0.87      0.88        30\n","          99       1.00      0.83      0.91        30\n","         100       0.70      0.95      0.81        20\n","         101       0.35      0.47      0.40        30\n","         102       0.70      0.47      0.56        30\n","         103       0.74      0.67      0.70        30\n","         104       0.67      0.53      0.59        19\n","         105       0.96      0.83      0.89        30\n","         106       0.39      0.43      0.41        30\n","         107       1.00      0.43      0.60        30\n","         108       0.96      0.90      0.93        30\n","         109       0.82      0.90      0.86        30\n","         110       0.57      0.80      0.67        30\n","         111       0.82      0.47      0.60        30\n","         112       0.73      0.95      0.83        20\n","         113       0.87      0.87      0.87        30\n","         114       0.78      0.62      0.69        29\n","         115       0.66      0.70      0.68        30\n","         116       0.66      0.72      0.69        29\n","         117       0.58      0.63      0.60        30\n","         118       0.56      0.66      0.60        29\n","         119       0.85      0.77      0.81        30\n","         120       0.78      0.60      0.68        30\n","         121       0.83      0.80      0.81        30\n","         122       0.85      0.73      0.79        30\n","         123       0.75      0.72      0.74        29\n","         124       0.67      0.76      0.71        29\n","         125       0.72      0.70      0.71        30\n","         126       0.75      0.40      0.52        30\n","         127       0.89      0.80      0.84        30\n","         128       0.69      0.80      0.74        30\n","         129       0.86      0.60      0.71        30\n","         130       0.46      0.87      0.60        30\n","         131       0.90      0.87      0.88        30\n","         132       0.93      0.90      0.92        30\n","         133       0.85      0.93      0.89        30\n","         134       0.52      0.47      0.49        30\n","         135       0.72      0.77      0.74        30\n","         136       0.61      0.63      0.62        30\n","         137       0.93      0.83      0.88        30\n","         138       0.65      0.73      0.69        30\n","         139       0.90      0.90      0.90        30\n","         140       0.59      0.69      0.63        29\n","         141       0.57      0.40      0.47        30\n","         142       0.48      0.53      0.51        30\n","         143       0.21      0.13      0.16        30\n","         144       0.39      0.50      0.44        30\n","         145       0.47      0.57      0.52        30\n","         146       0.66      0.90      0.76        30\n","         147       0.94      0.97      0.95        30\n","         148       0.93      0.86      0.89        29\n","         149       0.74      0.77      0.75        30\n","         150       0.76      0.90      0.83        21\n","         151       0.76      0.87      0.81        30\n","         152       0.69      0.69      0.69        29\n","         153       0.79      0.63      0.70        30\n","         154       0.69      0.83      0.76        30\n","         155       0.79      0.87      0.83        30\n","         156       0.74      0.69      0.71        29\n","         157       0.82      0.93      0.87        30\n","         158       0.94      0.97      0.95        30\n","         159       0.83      1.00      0.91        29\n","         160       0.78      0.70      0.74        30\n","         161       0.83      0.83      0.83        30\n","         162       0.93      0.90      0.92        30\n","         163       0.96      0.90      0.93        30\n","         164       0.92      0.80      0.86        30\n","         165       0.93      0.90      0.91        29\n","         166       0.83      0.67      0.74        30\n","         167       0.93      0.90      0.91        29\n","         168       0.89      0.86      0.88        29\n","         169       0.77      0.77      0.77        30\n","         170       0.96      0.83      0.89        30\n","         171       0.69      0.90      0.78        30\n","         172       0.55      0.57      0.56        30\n","         173       0.79      0.77      0.78        30\n","         174       0.65      0.80      0.72        30\n","         175       0.90      0.90      0.90        30\n","         176       0.93      0.90      0.92        30\n","         177       0.65      0.85      0.73        26\n","         178       0.52      0.45      0.48        29\n","         179       0.76      0.93      0.84        30\n","         180       0.85      0.76      0.80        29\n","         181       0.87      0.90      0.89        30\n","         182       0.81      0.87      0.84        30\n","         183       0.81      0.83      0.82        30\n","         184       0.93      0.87      0.90        30\n","         185       0.91      0.97      0.94        30\n","         186       0.89      0.85      0.87        20\n","         187       0.97      0.93      0.95        30\n","         188       0.88      0.97      0.92        30\n","         189       0.93      0.90      0.91        29\n","         190       1.00      0.87      0.93        30\n","         191       0.90      0.90      0.90        30\n","         192       0.64      0.60      0.62        30\n","         193       0.92      0.77      0.84        30\n","         194       0.68      0.87      0.76        30\n","         195       0.75      0.60      0.67        30\n","         196       0.63      0.80      0.71        30\n","         197       0.77      0.77      0.77        30\n","         198       0.71      0.90      0.79        30\n","         199       0.90      0.90      0.90        30\n","\n","    accuracy                           0.76      5794\n","   macro avg       0.77      0.76      0.76      5794\n","weighted avg       0.77      0.76      0.76      5794\n","\n"]}]},{"cell_type":"code","source":["confusion_matrix(ycorr, ypre)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uDArHLQwqdK","executionInfo":{"status":"ok","timestamp":1677814595082,"user_tz":0,"elapsed":25,"user":{"displayName":"Richard patrick","userId":"16822747536882988489"}},"outputId":"a9930974-0ab8-4a4c-c362-7371feecd7db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[15, 11,  2, ...,  0,  0,  0],\n","       [ 1, 24,  1, ...,  0,  0,  0],\n","       [ 3,  2, 20, ...,  0,  0,  0],\n","       ...,\n","       [ 0,  0,  0, ..., 21,  0,  0],\n","       [ 0,  0,  0, ...,  0, 22,  0],\n","       [ 0,  0,  0, ...,  0,  0, 25]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":[],"metadata":{"id":"tQDYaALTikmL"},"execution_count":null,"outputs":[]}]}